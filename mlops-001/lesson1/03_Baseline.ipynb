{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/edu/blob/main/mlops-001/lesson1/03_Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{course-lesson1} -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b1a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (run once)\n",
    "!wget https://raw.githubusercontent.com/wandb/edu/main/mlops-001/lesson1/requirements.txt\n",
    "!wget https://raw.githubusercontent.com/wandb/edu/main/mlops-001/lesson1/params.py\n",
    "!wget https://raw.githubusercontent.com/wandb/edu/main/mlops-001/lesson1/utils.py\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4723ae62-c55d-4c8f-9157-43c29189a2ff",
   "metadata": {},
   "source": [
    "# Baseline solution\n",
    "\n",
    "<!--- @wandbcode{course-lesson1} -->\n",
    "\n",
    "In this notebook we will create a baseline solution to our semantic segmentation problem. To iterate fast a notebook is a handy solution. We will then refactor this code into a script to be able to use hyperparameter sweeps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29116dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.wandb import WandbCallback\n",
    "\n",
    "import params\n",
    "from utils import get_predictions, create_iou_table, MIOU, BackgroundIOU, \\\n",
    "                  RoadIOU, TrafficLightIOU, TrafficSignIOU, PersonIOU, VehicleIOU, BicycleIOU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0871e5-c07d-4a8b-817b-388c2e9bf7d1",
   "metadata": {},
   "source": [
    "Again, we're importing some global configuration parameters from `params.py` file. We have also defined some helper functions in `utils.py` - for example metrics we will track during our experiments.\n",
    "\n",
    "Let's now create a `train_config` that we'll pass to W&B `run` to control training hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff6b8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = SimpleNamespace(\n",
    "    framework=\"fastai\",\n",
    "    img_size=(180, 320),\n",
    "    batch_size=8,\n",
    "    augment=True, # use data augmentation\n",
    "    epochs=10, \n",
    "    lr=2e-3,\n",
    "    pretrained=True,  # whether to use pretrained encoder\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f014f3-d78f-4f5b-b038-d8020de43930",
   "metadata": {},
   "source": [
    "We are setting seed for reproducibility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6765f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(train_config.seed, reproducible=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32483e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=params.WANDB_PROJECT, entity=params.ENTITY, job_type=\"training\", config=train_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7c1872-fc08-4304-9842-203d9ac45371",
   "metadata": {},
   "source": [
    "As usual, we will use W&B Artifacts to track the lineage of our models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df839467",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_at = run.use_artifact(f'{params.PROCESSED_DATA_AT}:latest')\n",
    "processed_dataset_dir = Path(processed_data_at.download())\n",
    "df = pd.read_csv(processed_dataset_dir / 'data_split.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77170345-96d3-4371-a4e9-5ea3b15e2cdb",
   "metadata": {},
   "source": [
    "We will not use the hold out dataset stage at this moment. `is_valid` column will tell our trainer how we want to split data between training and validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a34e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Stage != 'test'].reset_index(drop=True)\n",
    "df['is_valid'] = df.Stage == 'valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ae3d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_func(fname):\n",
    "    return (fname.parent.parent/\"labels\")/f\"{fname.stem}_mask.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fb25d8-50b0-4c14-9d52-d14725e024c9",
   "metadata": {},
   "source": [
    "We will use `fastai`'s `DataBlock` API to feed data into model training and validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f713864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign paths\n",
    "df[\"image_fname\"] = [processed_dataset_dir/f'images/{f}' for f in df.File_Name.values]\n",
    "df[\"label_fname\"] = [label_func(f) for f in df.image_fname.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4268334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df, bs=4, img_size=(180, 320), augment=True):\n",
    "    block = DataBlock(blocks=(ImageBlock, MaskBlock(codes=params.BDD_CLASSES)),\n",
    "                  get_x=ColReader(\"image_fname\"),\n",
    "                  get_y=ColReader(\"label_fname\"),\n",
    "                  splitter=ColSplitter(),\n",
    "                  item_tfms=Resize(img_size),\n",
    "                  batch_tfms=aug_transforms() if augment else None,\n",
    "                 )\n",
    "    return block.dataloaders(df, bs=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929f7975-ff29-4692-89b3-7f7596aecb0a",
   "metadata": {},
   "source": [
    "We are using `wandb.config` to track our training hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f214f2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58544078",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_data(df, bs=config.batch_size, img_size=config.img_size, augment=config.augment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475d4e69-d8ec-4093-a8e4-0f09b0979887",
   "metadata": {},
   "source": [
    "We will use *intersection over union* metrics: mean across all classes (MIOU) and IOU for each class separately. Our model will be a `unet` based on pretrained `resnet18` backbone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fd4610",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [MIOU(), BackgroundIOU(), RoadIOU(), TrafficLightIOU(), \\\n",
    "           TrafficSignIOU(), PersonIOU(), VehicleIOU(), BicycleIOU()]\n",
    "\n",
    "learn = unet_learner(dls, arch=resnet18, pretrained=config.pretrained, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d45330-cfc2-44e9-8c0c-5eee417050b1",
   "metadata": {},
   "source": [
    "In `fastai` we already have a callback that integrates tightly with W&B, we only need to pass the `WandbCallback` to the learner and we are ready to go. The callback will log all the useful variables for us. For example, whatever metric we pass to the learner will be tracked by the callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87db7e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    SaveModelCallback(monitor='miou'),\n",
    "    WandbCallback(log_preds=False, log_model=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfe3c60-f4af-4e21-874d-13f119d03dd5",
   "metadata": {},
   "source": [
    "Let's train our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1846493",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(config.epochs, config.lr, cbs=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976ac11f-ad6c-4f9d-b2b0-6acb8d7af34a",
   "metadata": {},
   "source": [
    "We will log a table with model predictions and ground truth to W&B, so that we can do error analysis in the W&B dashboard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387dc2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, outputs, predictions = get_predictions(learn)\n",
    "table = create_iou_table(samples, outputs, predictions, params.BDD_CLASSES)\n",
    "wandb.log({\"pred_table\":table})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b913a7ca-1250-4a61-a011-d333110bb927",
   "metadata": {},
   "source": [
    "We are reloading the model from the best checkpoint at the end and saving it. To make sure we track the final metrics correctly, we will validate the model again and save the final loss and metrics to `wandb.summary`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ec120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = learn.validate()\n",
    "metric_names = ['final_loss'] + [f'final_{x.name}' for x in metrics]\n",
    "final_results = {metric_names[i] : scores[i] for i in range(len(scores))}\n",
    "for k,v in final_results.items(): \n",
    "    wandb.summary[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f86720",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
