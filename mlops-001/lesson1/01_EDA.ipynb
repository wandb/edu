{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PA8brbxOz-_p"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wandb/edu/blob/main/mlops-001/lesson1/01_EDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "<!--- @wandbcode{course-lesson1} -->"
      ],
      "id": "PA8brbxOz-_p"
    },
    {
      "cell_type": "markdown",
      "id": "a212966e-8f38-4b4a-8e00-2985120439ca",
      "metadata": {
        "id": "a212966e-8f38-4b4a-8e00-2985120439ca"
      },
      "source": [
        "# EDA \n",
        "<!--- @wandbcode{course-lesson1} -->\n",
        "\n",
        "In this notebook, we will download a sample of the [BDD100K](https://www.bdd100k.com/) semantic segmentation dataset and use W&B Artifacts and Tables to version and analyze our data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17490b58-a8f2-489e-9c71-ca0e078591dc",
      "metadata": {
        "id": "17490b58-a8f2-489e-9c71-ca0e078591dc"
      },
      "outputs": [],
      "source": [
        "DEBUG = False # set this flag to True to use a small subset of data for testing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "NNdrW4Ifz_6z",
        "outputId": "286d2b1d-6bf7-449a-dd9c-b4cfbb8fd7f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "NNdrW4Ifz_6z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.14.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.17.0-py2.py3-none-any.whl (189 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.1/189.1 KB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb) (63.4.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from wandb) (4.5.0)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.27.1)\n",
            "Collecting appdirs>=1.4.3\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (5.9.4)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.19.6)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=e7cda4492bfa4f7fadfd431141f882d9ec3625d17c59bbc592db537d230463d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n",
            "Successfully built pathtools\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ee88efc-3257-4ed7-bb8c-1695f4a8c828",
      "metadata": {
        "id": "7ee88efc-3257-4ed7-bb8c-1695f4a8c828"
      },
      "outputs": [],
      "source": [
        "from fastai.vision.all import *\n",
        "import params\n",
        "\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "055764da-7252-4796-86af-585007dea288",
      "metadata": {
        "id": "055764da-7252-4796-86af-585007dea288"
      },
      "source": [
        "We have defined some global configuration parameters in the `params.py` file. `ENTITY` should correspond to your W&B Team name if you work in a team, replace it with `None` if you work individually. \n",
        "\n",
        "In the section below, we will use `untar_data` function from `fastai` to download and unzip our datasets. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bae3750-a653-4265-9c52-c1f9af9b8393",
      "metadata": {
        "id": "0bae3750-a653-4265-9c52-c1f9af9b8393"
      },
      "outputs": [],
      "source": [
        "URL = 'https://storage.googleapis.com/wandb_course/bdd_simple_1k.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0da50d19-860a-4b39-8320-a376c483da04",
      "metadata": {
        "id": "0da50d19-860a-4b39-8320-a376c483da04"
      },
      "outputs": [],
      "source": [
        "path = Path(untar_data(URL, force_download=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6df5b830-e685-4a0d-81e8-6dda10697dff",
      "metadata": {
        "id": "6df5b830-e685-4a0d-81e8-6dda10697dff"
      },
      "outputs": [],
      "source": [
        "path.ls()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db6708ae-abaa-432f-83b0-028a99222096",
      "metadata": {
        "id": "db6708ae-abaa-432f-83b0-028a99222096"
      },
      "source": [
        "Here we define several functions to help us process the data and upload it as a `Table` to W&B. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5779f980-4d9b-4645-9726-642a25334e10",
      "metadata": {
        "id": "5779f980-4d9b-4645-9726-642a25334e10"
      },
      "outputs": [],
      "source": [
        "def label_func(fname):\n",
        "    return (fname.parent.parent/\"labels\")/f\"{fname.stem}_mask.png\"\n",
        "\n",
        "def get_classes_per_image(mask_data, class_labels):\n",
        "    unique = list(np.unique(mask_data))\n",
        "    result_dict = {}\n",
        "    for _class in class_labels.keys():\n",
        "        result_dict[class_labels[_class]] = int(_class in unique)\n",
        "    return result_dict\n",
        "\n",
        "def _create_table(image_files, class_labels):\n",
        "    \"Create a table with the dataset\"\n",
        "    labels = [str(class_labels[_lab]) for _lab in list(class_labels)]\n",
        "    table = wandb.Table(columns=[\"File_Name\", \"Images\", \"Split\"] + labels)\n",
        "    \n",
        "    for i, image_file in progress_bar(enumerate(image_files), total=len(image_files)):\n",
        "        image = Image.open(image_file)\n",
        "        mask_data = np.array(Image.open(label_func(image_file)))\n",
        "        class_in_image = get_classes_per_image(mask_data, class_labels)\n",
        "        table.add_data(\n",
        "            str(image_file.name),\n",
        "            wandb.Image(\n",
        "                    image,\n",
        "                    masks={\n",
        "                        \"predictions\": {\n",
        "                            \"mask_data\": mask_data,\n",
        "                            \"class_labels\": class_labels,\n",
        "                        }\n",
        "                    }\n",
        "            ),\n",
        "            \"None\", # we don't have a dataset split yet\n",
        "            *[class_in_image[_lab] for _lab in labels]\n",
        "        )\n",
        "    \n",
        "    return table"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eac085cd-2409-4baf-a887-108e3dca65b9",
      "metadata": {
        "id": "eac085cd-2409-4baf-a887-108e3dca65b9"
      },
      "source": [
        "We will start a new W&B `run` and put everything into a raw Artifact."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e87141b3-b9b7-4a40-839c-64c835484f48",
      "metadata": {
        "id": "e87141b3-b9b7-4a40-839c-64c835484f48"
      },
      "outputs": [],
      "source": [
        "run = wandb.init(project=params.WANDB_PROJECT, entity=params.ENTITY, job_type=\"upload\")\n",
        "raw_data_at = wandb.Artifact(params.RAW_DATA_AT, type=\"raw_data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2de6968-b465-4e2e-aaf1-787a48c7981e",
      "metadata": {
        "id": "f2de6968-b465-4e2e-aaf1-787a48c7981e"
      },
      "outputs": [],
      "source": [
        "raw_data_at.add_file(path/'LICENSE.txt', name='LICENSE.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10addc71-201d-4c29-af23-9a5d9a5cbddf",
      "metadata": {
        "id": "10addc71-201d-4c29-af23-9a5d9a5cbddf"
      },
      "source": [
        "Let's add the images and label masks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2e29a83-ec60-4518-8b73-078f1719bc8f",
      "metadata": {
        "id": "e2e29a83-ec60-4518-8b73-078f1719bc8f"
      },
      "outputs": [],
      "source": [
        "raw_data_at.add_dir(path/'images', name='images')\n",
        "raw_data_at.add_dir(path/'labels', name='labels')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01b989eb-36da-4194-9a34-88126749f210",
      "metadata": {
        "id": "01b989eb-36da-4194-9a34-88126749f210"
      },
      "source": [
        "Let's get the file names of images in our dataset and use the function we defined above to create a W&B Table. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeaa2dae-1b2b-4c70-8dcf-b079f4f05b86",
      "metadata": {
        "id": "aeaa2dae-1b2b-4c70-8dcf-b079f4f05b86"
      },
      "outputs": [],
      "source": [
        "image_files = get_image_files(path/\"images\", recurse=False)\n",
        "\n",
        "# sample a subset if DEBUG\n",
        "if DEBUG: image_files = image_files[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "451ff088-4cb3-4739-b4e8-308d03645ffe",
      "metadata": {
        "id": "451ff088-4cb3-4739-b4e8-308d03645ffe"
      },
      "outputs": [],
      "source": [
        "table = _create_table(image_files, params.BDD_CLASSES)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff73cd37-6a72-44f7-a5cf-6abe7d327092",
      "metadata": {
        "id": "ff73cd37-6a72-44f7-a5cf-6abe7d327092"
      },
      "source": [
        "Finally, we will add the Table to our Artifact, log it to W&B and finish our `run`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4183e9c-75e4-48a8-a2e1-0f4492c0b5d0",
      "metadata": {
        "id": "d4183e9c-75e4-48a8-a2e1-0f4492c0b5d0"
      },
      "outputs": [],
      "source": [
        "raw_data_at.add(table, \"eda_table\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e81ed9c8-6905-4841-a9f7-e3f3b9b6d927",
      "metadata": {
        "id": "e81ed9c8-6905-4841-a9f7-e3f3b9b6d927"
      },
      "outputs": [],
      "source": [
        "run.log_artifact(raw_data_at)\n",
        "run.finish()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}