{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/edu/blob/main/mlops-001/lesson1/02_Split.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{course-lesson1} -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee477f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (run once)\n",
    "!wget https://raw.githubusercontent.com/wandb/edu/main/mlops-001/lesson1/requirements.txt\n",
    "!wget https://raw.githubusercontent.com/wandb/edu/main/mlops-001/lesson1/params.py\n",
    "!wget https://raw.githubusercontent.com/wandb/edu/main/mlops-001/lesson1/utils.py\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cc5437-1a17-4738-a3c7-f1959324f4ed",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "<!--- @wandbcode{course-lesson1} -->\n",
    "\n",
    "In this notebook we will prepare the data to later train our deep learning model. To do so,\n",
    "\n",
    "- we will start a new W&B `run` and use our raw data artifact\n",
    "- split the data and save the splits into a new W&B Artifact\n",
    "- join information about the split with our EDA Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8018ee4-8f0f-4e1d-a39d-d005bc9b4591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "import wandb\n",
    "\n",
    "import pandas as pd\n",
    "from fastai.vision.all import *\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "import params\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423709e6-1f8c-4b90-8a7b-6ed6c05492ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=params.WANDB_PROJECT, entity=params.ENTITY, job_type=\"data_split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b9419f-e0cc-4e57-b0f4-e9273fec996b",
   "metadata": {},
   "source": [
    "Let's use artifact we previously saved to W&B (we're storing artifact names and other global parameters in `params`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7841e7a1-188e-4021-9c2b-b662b7a13a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_at = run.use_artifact(f'{params.RAW_DATA_AT}:latest')\n",
    "path = Path(raw_data_at.download())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160fcb5d-3a3b-40a6-b131-60b33ea3b530",
   "metadata": {},
   "outputs": [],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbbb8be-49cc-46c2-b563-b90d14892708",
   "metadata": {},
   "source": [
    "To split data between training, testing and validation, we need file names, groups (derived from the file name) and target (here we use our rare class bicycle for stratification). We previously saved these columns to EDA table, so let's retrieve it from the table now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156ac385-610f-43c8-ab3a-8ab91a1cbc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = os.listdir(path/'images')\n",
    "groups = [s.split('-')[0] for s in fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d93918-c51e-4501-9b2a-9ea87ae1184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_eda_table = raw_data_at.get(\"eda_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a31eef6-725a-4eaa-9bb4-bec9aeaf4414",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = orig_eda_table.get_column('bicycle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735730ed-e4c0-4ca6-82be-22a517cd74bc",
   "metadata": {},
   "source": [
    "Now we will split the data into train (80%), validation (10%) and test (10%) sets. As we do that, we need to be careful to:\n",
    "\n",
    "- *avoid leakage*: for that reason we are grouping data according to video identifier (we want to make sure our model can generalize to new cars or video frames)\n",
    "- handle the *label imbalance*: for that reason we stratify data with our target column\n",
    "\n",
    "We will use sklearn's `StratifiedGroupKFold` to split the data into 10 folds and assign 1 fold for test, 1 for validation and the rest for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af79361-0aea-4ecd-bfaf-3bc034286cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['File_Name'] = fnames\n",
    "df['fold'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09ceb74-d7dc-4a3b-9bca-7a30f3a1de23",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedGroupKFold(n_splits=10)\n",
    "for i, (train_idxs, test_idxs) in enumerate(cv.split(fnames, y, groups)):\n",
    "    df.loc[test_idxs, ['fold']] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced2899d-dc7e-4769-92e5-f0eaf585a4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Stage'] = 'train'\n",
    "df.loc[df.fold == 0, ['Stage']] = 'test'\n",
    "df.loc[df.fold == 1, ['Stage']] = 'valid'\n",
    "del df['fold']\n",
    "df.Stage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b322c8d-dab6-4f21-8b0b-22fac2de3aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_split.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fd8322-a52b-4f69-a716-04ce4b4ffb5b",
   "metadata": {},
   "source": [
    "We will now create a new artifact and add our data there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7369b2a4-6c0b-44fb-8850-c8bfebd105ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_at = wandb.Artifact(params.PROCESSED_DATA_AT, type=\"split_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b264b216-ef03-4417-88df-6fc27865c1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_at.add_file('data_split.csv')\n",
    "processed_data_at.add_dir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df4949c-c9de-4e0b-990e-58e98b2121e3",
   "metadata": {},
   "source": [
    "Finally, the split information may be relevant for our analyses - rather than uploading images again, we will save the split information to a new table and join it with EDA table we created previously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818a359a-6b54-4f65-b5d9-732bbe5eb91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split_table = wandb.Table(dataframe=df[['File_Name', 'Stage']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedc9255-2ee3-4015-bdd3-a8449a120895",
   "metadata": {},
   "outputs": [],
   "source": [
    "join_table = wandb.JoinedTable(orig_eda_table, data_split_table, \"File_Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998b2369-d11b-4fef-a709-69cdc333ee1b",
   "metadata": {},
   "source": [
    "Let's add it to our artifact, log it and finish our `run`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42157919-05b2-4e28-8dc4-350160c0ae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_at.add(join_table, \"eda_table_data_split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6745c3-1ab6-4ebf-8f89-07d6da09fe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_artifact(processed_data_at)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299d71f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
