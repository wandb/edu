{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "emotion-classifier.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPSs+zVVD8hcx3JMZsSMZTn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wandb/edu/blob/main/lightning/projects/emotion_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS5-7kZVPYn6"
      },
      "source": [
        "<img src=\"https://i.imgur.com/gb6B4ig.png\" width=\"400\" alt=\"Weights & Biases\" />\n",
        "\n",
        "# Emotion Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwl91FcAPxKC"
      },
      "source": [
        "%%capture\n",
        "!pip install pytorch_lightning torchviz wandb\n",
        "\n",
        "repo_url = \"https://raw.githubusercontent.com/wandb/edu/main/\"\n",
        "utils_path = \"lightning/utils.py\"\n",
        "# Download a util file of helper methods for this notebook\n",
        "!curl {repo_url + utils_path} --output utils.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bWIJyxrPRku"
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import pytorch_lightning as pl\n",
        "import numpy as np\n",
        "import subprocess\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import torchvision.datasets\n",
        "import os\n",
        "\n",
        "import wandb\n",
        "\n",
        "import utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDvJlwRlUg9c"
      },
      "source": [
        "## Facial Expression `DataModule` and `DataLoaders`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMDEO9ekRiAR"
      },
      "source": [
        "class FERDataModule(pl.LightningDataModule):\n",
        "  \"\"\"DataModule for downloading and preparing the FER2013 dataset.\n",
        "  \"\"\"\n",
        "  tar_url = \"https://www.dropbox.com/s/opuvvdv3uligypx/fer2013.tar\"\n",
        "  local_path = Path(\"fer2013\")\n",
        "\n",
        "  def __init__(self, batch_size=64):\n",
        "    super().__init__()  # ‚ö°: we inherit from LightningDataModule\n",
        "    self.batch_size = batch_size\n",
        "    self.val_batch_size = 10 * self.batch_size\n",
        "\n",
        "  def prepare_data(self, validation_size=0.2, force_reload=False):\n",
        "    # ‚ö°: how do we set up the data?\n",
        "    if hasattr(self, \"training_data\") and not force_reload:\n",
        "      return  # only re-run if we haven't been run before\n",
        "\n",
        "    # download the data from the internet\n",
        "    self.download_data()\n",
        "\n",
        "    # read it from a .csv file\n",
        "    faces, emotions = self.read_data()\n",
        "\n",
        "    # normalize it\n",
        "    faces = torch.divide(faces, 255.)\n",
        "\n",
        "    # split it into training and validation\n",
        "    validation_size = int(len(faces) * 0.8)\n",
        "\n",
        "    self.training_data = torch.utils.data.TensorDataset(\n",
        "      faces[:-validation_size], emotions[:-validation_size])\n",
        "    self.validation_data = torch.utils.data.TensorDataset(\n",
        "      faces[-validation_size:], emotions[-validation_size:])\n",
        "    \n",
        "    # record metadata\n",
        "    self.num_total, self.num_classes = emotions.shape[0], torch.max(emotions)\n",
        "    self.num_train = self.num_total - validation_size\n",
        "    self.num_validation = validation_size\n",
        "\n",
        "  def train_dataloader(self):  # ‚ö°: how do we go from dataset to dataloader?\n",
        "    \"\"\"The DataLoaders returned by a DataModule produce data for a model.\n",
        "    \n",
        "    This DataLoader is used during training.\"\"\"\n",
        "    return DataLoader(self.training_data, batch_size=self.batch_size)\n",
        "\n",
        "  def val_dataloader(self):  # ‚ö°: what about during validation?\n",
        "    \"\"\"The DataLoaders returned by a DataModule produce data for a model.\n",
        "    \n",
        "    This DataLoader is used during validation, at the end of each epoch.\"\"\"\n",
        "    return DataLoader(self.validation_data, batch_size=self.val_batch_size)\n",
        "\n",
        "  def download_data(self):\n",
        "    if not os.path.exists(self.local_path):\n",
        "      print(\"Downloading the face emotion dataset...\")\n",
        "      subprocess.check_output(\n",
        "          f\"curl -SL {self.tar_url} | tar xz\", shell=True)\n",
        "      print(\"...done\")\n",
        "      \n",
        "  def read_data(self):\n",
        "    \"\"\"Read the data from a .csv into torch Tensors\"\"\"\n",
        "    data = pd.read_csv(self.local_path / \"fer2013.csv\")\n",
        "    pixels = data[\"pixels\"].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = np.asarray(pixel_sequence.split(\n",
        "            ' '), dtype=np.uint8).reshape(width, height)\n",
        "        faces.append(face.astype(\"float32\"))\n",
        "\n",
        "    faces = np.asarray(faces)\n",
        "    emotions = data[\"emotion\"].to_numpy()\n",
        "\n",
        "    return torch.tensor(faces), torch.tensor(emotions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiykCpNiW_RT"
      },
      "source": [
        "## Defining the `Model`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZIcFSsZQ3rz"
      },
      "source": [
        "class LitEmotionClassifier(utils.LoggedImageClassifierModule):\n",
        "\n",
        "  def __init__(self, config, max_images_to_display=32):\n",
        "    super().__init__(max_images_to_display=max_images_to_display)\n",
        "    self.linear = torch.nn.Linear(48 * 48 * 1, 7)\n",
        "    self.labels = [\"Angry\", \"Disgusted\", \"Afraid\", \"Happy\",\n",
        "                   \"Sad\", \"Surprised\", \"Neutral\"]\n",
        "\n",
        "    self.optimizer = config[\"optimizer\"]\n",
        "    self.optimizer_params = config[\"optimizer.params\"]\n",
        "    self.loss = config[\"loss\"]\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = torch.flatten(x, start_dim=1)\n",
        "    x = self.linear(x)\n",
        "    return F.log_softmax(x, dim=1)\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    return self.optimizer(self.parameters(), **self.optimizer_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zr6c9o7X9C6"
      },
      "source": [
        "## Building the `Model` and Loading the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8rAPoX-YHBu"
      },
      "source": [
        "config = {\n",
        "  \"batch_size\": 256,\n",
        "  \"max_epochs\": 10,\n",
        "  \"activation\": torch.nn.ReLU(),\n",
        "  \"loss\": torch.nn.NLLLoss(),\n",
        "  \"optimizer\": torch.optim.Adam,\n",
        "  \"optimizer.params\": {\"lr\": 0.001},\n",
        "}\n",
        "\n",
        "dmodule = FERDataModule(batch_size=config[\"batch_size\"])\n",
        "lec = LitEmotionClassifier(config)\n",
        "dmodule.prepare_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQMzEoEyU_4t"
      },
      "source": [
        "### Debugging Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "067CRKkuVBxh"
      },
      "source": [
        "# for debugging purposes (checking shapes, etc.), make these available\n",
        "dloader = dmodule.train_dataloader()  # set up the Loader\n",
        "\n",
        "example_batch = next(iter(dloader))  # grab a batch from the Loader\n",
        "example_x, example_y = example_batch[0].to(\"cuda\"), example_batch[1].to(\"cuda\")\n",
        "\n",
        "print(f\"Input Shape: {example_x.shape}\")\n",
        "print(f\"Target Shape: {example_y.shape}\")\n",
        "\n",
        "lec.to(\"cuda\")\n",
        "outputs = lec.forward(example_x)\n",
        "print(f\"Output Shape: {outputs.shape}\")\n",
        "print(f\"Loss : {lec.loss(outputs, example_y)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eV4GL75Z-TH"
      },
      "source": [
        "### Running `.fit`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1rA-q1FaAam"
      },
      "source": [
        "# üëü configure Trainer \n",
        "trainer = pl.Trainer(gpus=1,  # use the GPU for .forward\n",
        "                     logger=pl.loggers.WandbLogger(\n",
        "                       project=\"lit-fer\", entity=\"wandb\", config=config,\n",
        "                       save_code=True),  # log to Weights & Biases\n",
        "                     max_epochs=config[\"max_epochs\"], log_every_n_steps=1)\n",
        "\n",
        "# üèÉ‚Äç‚ôÄÔ∏è run the Trainer on the model\n",
        "trainer.fit(lec, dmodule)\n",
        "\n",
        "# üíæ save the model\n",
        "torch.save(lec, \"model.pt\")\n",
        "wandb.save(\"model.pt\")\n",
        "\n",
        "# üèÅ close out the run\n",
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}