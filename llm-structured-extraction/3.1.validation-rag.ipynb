{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28b539d5",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/edu/blob/main/llm-structured-extraction/3.1.validation-rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{llmeng-1-nb4} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a01f3ac-5306-4a1b-9e47-a5d254bce93a",
   "metadata": {},
   "source": [
    "# Understanding Validators and controlling responses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcc78ac-ed6d-49e3-b71b-fb2fb25f16a8",
   "metadata": {},
   "source": [
    "Previously we went over how to use structured Extraction to Query and Plan a search request\n",
    "\n",
    "In this section we'll aim to \n",
    "\n",
    "1. Expand on how Pydantic's validation features work\n",
    "2. Apply them to generate better responses by using feedback and validation.\n",
    "\n",
    "Pydantic offers a customizable and expressive validation framework for Python. Instructor leverages Pydantic's validation framework to provide a uniform developer experience for both code-based and LLM-based validation, as well as a reasking mechanism for correcting LLM outputs based on validation errors. To learn more check out the Pydantic [docs](https://docs.pydantic.dev/latest/) on validators.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064c286b",
   "metadata": {},
   "source": [
    "Validators will enable us to control outputs by defining a function like so:\n",
    "\n",
    "```python\n",
    "def validation_function(value):\n",
    "    if condition(value):\n",
    "        raise ValueError(\"Value is not valid\")\n",
    "    return mutation(value)\n",
    "```\n",
    "\n",
    "Before we get started lets go over the general shape of a validator:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f5da29",
   "metadata": {},
   "source": [
    "# Setup Colab\n",
    "\n",
    "Run this code if you're using Google Colab, you can skip if you're running locally. You may need to restart Colab after installing requirements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "238348d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Download files on colab\n",
    "if not Path(\"requirements.txt\").exists():\n",
    "    !wget https://raw.githubusercontent.com/wandb/edu/main/llm-structured-extraction/{requirements.txt,helpers.py}\n",
    "    !pip install -r requirements.txt -Uqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbbd5669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter password in the VS Code prompt at the top of your VS Code window!\n",
      "OpenAI API key configured\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "import openai\n",
    "\n",
    "# Setup your Openai API key\n",
    "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
    "  if any(['VSCODE' in x for x in os.environ.keys()]):\n",
    "    print('Please enter password in the VS Code prompt at the top of your VS Code window!')\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass(\"Paste your OpenAI key from: https://platform.openai.com/account/api-keys\\n\")\n",
    "  openai.api_key = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "\n",
    "assert os.getenv(\"OPENAI_API_KEY\", \"\").startswith(\"sk-\"), \"This doesn't look like a valid OpenAI API key\"\n",
    "print(\"OpenAI API key configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37a36f7",
   "metadata": {},
   "source": [
    "## Using Weave for LLM Experiment Tracking\n",
    "\n",
    "[Weave](https://wandb.github.io/weave/) is a lightweight toolkit by Weights & Biases for tracking and evaluating LLM applications. It allows you to:\n",
    "\n",
    "- Log and debug language model inputs, outputs, and traces\n",
    "- Build rigorous evaluations for LLM use cases\n",
    "- Organize information across the LLM workflow\n",
    "\n",
    "OpenAI calls are automatically logged to Weave.\n",
    "`@weave.op()` allows you to log additional information to Weave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7d05c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as Weights & Biases user: a-sh0ts.\n",
      "View Weave data at https://wandb.ai/a-sh0ts/llmeng-1-nb4/weave\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<weave.weave_client.WeaveClient at 0x147294590>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import weave\n",
    "weave.init(\"llmeng-1-nb4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfc6c66",
   "metadata": {},
   "source": [
    "## Defining Validator Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4bb6258-b03a-4621-8a73-29056a20ec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Annotated\n",
    "from pydantic import BaseModel, AfterValidator, WithJsonSchema\n",
    "\n",
    "\n",
    "def name_must_contain_space(v: str) -> str:\n",
    "    if \" \" not in v:\n",
    "        raise ValueError(\"Name must contain a space.\")\n",
    "    return v\n",
    "\n",
    "def uppercase_name(v: str) -> str:\n",
    "    return v.upper()\n",
    "\n",
    "FullName = Annotated[\n",
    "    str, \n",
    "    AfterValidator(name_must_contain_space), \n",
    "    AfterValidator(uppercase_name),\n",
    "    WithJsonSchema(\n",
    "        {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The user's full name\",\n",
    "        }\n",
    "    )]\n",
    "\n",
    "class UserDetail(BaseModel):\n",
    "    age: int\n",
    "    name: FullName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23f8cadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserDetail(age=30, name='JASON LIU')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UserDetail(age=30, name=\"Jason Liu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4f53ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'age': {'title': 'Age', 'type': 'integer'},\n",
       "  'name': {'description': \"The user's full name\",\n",
       "   'title': 'Name',\n",
       "   'type': 'string'}},\n",
       " 'required': ['age', 'name'],\n",
       " 'title': 'UserDetail',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UserDetail.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2284a7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 validation error for UserDetail\n",
      "name\n",
      "  Value error, Name must contain a space. [type=value_error, input_value='Jason', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.8/v/value_error\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    person = UserDetail.model_validate({\"age\": 24, \"name\": \"Jason\"})\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0302ca",
   "metadata": {},
   "source": [
    "## Using Field\n",
    "\n",
    "We can also use the `Field` class to define validators. This is useful when we want to define a validator for a field that is primitive, like a string or integer which supports a limited number of validators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3242856f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 validation errors for UserDetail\n",
      "age\n",
      "  Input should be greater than 0 [type=greater_than, input_value=-10, input_type=int]\n",
      "    For further information visit https://errors.pydantic.dev/2.8/v/greater_than\n",
      "name\n",
      "  Value error, Name must contain a space. [type=value_error, input_value='Jason', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.8/v/value_error\n"
     ]
    }
   ],
   "source": [
    "from pydantic import Field\n",
    "\n",
    "\n",
    "Age = Annotated[int, Field(gt=0)]\n",
    "\n",
    "class UserDetail(BaseModel):\n",
    "    age: Age\n",
    "    name: FullName\n",
    "\n",
    "try:\n",
    "    person = UserDetail(age=-10, name=\"Jason\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f689121",
   "metadata": {},
   "source": [
    "## Providing Context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec043c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import ValidationInfo\n",
    "\n",
    "def message_cannot_have_blacklisted_words(v: str, info: ValidationInfo) -> str:\n",
    "    blacklist = info.context.get(\"blacklist\", [])\n",
    "    for word in blacklist:\n",
    "        assert word not in v.lower(), f\"`{word}` was found in the message `{v}`\"\n",
    "    return v\n",
    "\n",
    "ModeratedStr = Annotated[str, AfterValidator(message_cannot_have_blacklisted_words)]\n",
    "\n",
    "class Response(BaseModel):\n",
    "    message: ModeratedStr\n",
    "\n",
    "\n",
    "try:\n",
    "    Response.model_validate(\n",
    "        {\"message\": \"I will hurt them.\"},\n",
    "        context={\n",
    "            \"blacklist\": {\n",
    "                \"rob\",\n",
    "                \"steal\",\n",
    "                \"kill\",\n",
    "                \"attack\",\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e3a638-c9c9-44cd-bcd0-ad1a39f448db",
   "metadata": {},
   "source": [
    "## Using OpenAI Moderation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d0b816-7ec8-42b0-9b91-c9aab382c960",
   "metadata": {},
   "source": [
    "To enhance our validation measures, we'll extend the scope to flag any answer that contains hateful content, harassment, or similar issues. OpenAI offers a moderation endpoint that addresses these concerns, and it's freely available when using OpenAI models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f46eb5",
   "metadata": {},
   "source": [
    "With the `instructor` library, this is just one function edit away:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82521112-5301-4442-acce-82b495bd838f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 validation error for Response\n",
      "message\n",
      "  Value error, `I want to make them suffer the consequences` was flagged for violence [type=value_error, input_value='I want to make them suffer the consequences', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.8/v/value_error\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from pydantic import AfterValidator\n",
    "from instructor import openai_moderation\n",
    "\n",
    "import instructor\n",
    "from openai import OpenAI\n",
    "\n",
    "client = instructor.patch(OpenAI())\n",
    "\n",
    "# This uses Annotated which is a new feature in Python 3.9\n",
    "# To define custom metadata for a type hint.\n",
    "ModeratedStr = Annotated[str, AfterValidator(openai_moderation(client=client))]\n",
    "\n",
    "\n",
    "class Response(BaseModel):\n",
    "    message: ModeratedStr\n",
    "\n",
    "\n",
    "try:\n",
    "    Response(message=\"I want to make them suffer the consequences\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa5116e",
   "metadata": {},
   "source": [
    "## General Validator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49d8b772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍩 https://wandb.ai/a-sh0ts/llmeng-1-nb4/r/call/4357cfa3-17bf-415f-a966-a3fa0ccf030e\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for AssistantMessage\nmessage\n  Assertion failed, The statement does not follow the rule of only discussing health best practices and topics. [type=assertion_error, input_value='I would suggest you to v...is very nice in winter.', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.8/v/assertion_error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAssistantMessage\u001b[39;00m(BaseModel):\n\u001b[1;32m     15\u001b[0m     message: HealthTopicStr\n\u001b[0;32m---> 18\u001b[0m \u001b[43mAssistantMessage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mI would suggest you to visit Sicily as they say it is very nice in winter.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     20\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/edu/.venv/lib/python3.12/site-packages/pydantic/main.py:193\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    192\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for AssistantMessage\nmessage\n  Assertion failed, The statement does not follow the rule of only discussing health best practices and topics. [type=assertion_error, input_value='I would suggest you to v...is very nice in winter.', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.8/v/assertion_error"
     ]
    }
   ],
   "source": [
    "from instructor import llm_validator\n",
    "\n",
    "HealthTopicStr = Annotated[\n",
    "    str,\n",
    "    AfterValidator(\n",
    "        llm_validator(\n",
    "            \"don't talk about any other topic except health best practices and topics\",\n",
    "            client=client,\n",
    "        )\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "class AssistantMessage(BaseModel):\n",
    "    message: HealthTopicStr\n",
    "\n",
    "\n",
    "AssistantMessage(\n",
    "    message=\"I would suggest you to visit Sicily as they say it is very nice in winter.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050e72fe-4b13-4002-a1d0-94f7b88b784b",
   "metadata": {},
   "source": [
    "### Avoiding hallucination with citations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f2869e-c8a3-4b93-82e7-55eb70930900",
   "metadata": {},
   "source": [
    "When incorporating external knowledge bases, it's crucial to ensure that the agent uses the provided context accurately and doesn't fabricate responses. Validators can be effectively used for this purpose. We can illustrate this with an example where we validate that a provided citation is actually included in the referenced text chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "638fc368-5cf7-4ae7-9d3f-efea1b84eec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 validation error for AnswerWithCitation\n",
      "citation\n",
      "  Value error, Citation `Jason is a cool person` not found in text, only use citations from the text. [type=value_error, input_value='Jason is a cool person', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.8/v/value_error\n"
     ]
    }
   ],
   "source": [
    "from pydantic import ValidationInfo\n",
    "\n",
    "def citation_exists(v: str, info: ValidationInfo):\n",
    "    context = info.context\n",
    "    if context:\n",
    "        context = context.get(\"text_chunk\")\n",
    "        if v not in context:\n",
    "            raise ValueError(f\"Citation `{v}` not found in text, only use citations from the text.\")\n",
    "    return v\n",
    "\n",
    "Citation = Annotated[\n",
    "    str,\n",
    "    AfterValidator(citation_exists),\n",
    "    WithJsonSchema({\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"For every answer provide an exact substring match to the context\"\n",
    "    })\n",
    "]\n",
    "\n",
    "\n",
    "class AnswerWithCitation(BaseModel):\n",
    "    answer: str\n",
    "    citation: Citation\n",
    "\n",
    "try:\n",
    "    AnswerWithCitation.model_validate(\n",
    "        {\n",
    "            \"answer\": \"Jason is cool\",\n",
    "            \"citation\": \"Jason is a cool person\",\n",
    "        },\n",
    "        context={\"text_chunk\": \"Jason is just a normal guy\"},\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3064b06b-7f85-40ec-8fe2-4fa2cce36585",
   "metadata": {},
   "source": [
    "Here we assume that there is a \"text_chunk\" field that contains the text that the model is supposed to use as context. We then use the `field_validator` decorator to define a validator that checks if the citation is included in the text chunk. If it's not, we raise a `ValueError` with a message that will be returned to the user.\n",
    "\n",
    "\n",
    "If we want to pass in the context through the `chat.completions.create`` endpoint, we can use the `validation_context` parameter\n",
    "\n",
    "```python\n",
    "resp = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    response_model=AnswerWithCitation,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"Answer the question `{q}` using the text chunk\\n`{text_chunk}`\"},\n",
    "    ],\n",
    "    validation_context={\"text_chunk\": text_chunk},\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d15ad2",
   "metadata": {},
   "source": [
    "In practice there are many ways to implement this: we could use a regex to check if the citation is included in the text chunk, or we could use a more sophisticated approach like a semantic similarity check. The important thing is that we have a way to validate that the model is using the provided context accurately.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbbaa11-32d2-4772-bc31-18d1d6d6c919",
   "metadata": {},
   "source": [
    "## Reasking with validators\n",
    "\n",
    "For most of these examples all we've done we've mostly only defined the validation logic. Which can be seperate from generation, however when we are given validation errors, we shouldn't end there! Instead instructor allows us to collect all the validation errors and reask the llm to rewrite their answer.\n",
    "\n",
    "Lets try to use an extreme example to illustrate this point:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97f544e7-2552-465c-89a9-a4820f00d658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍩 https://wandb.ai/a-sh0ts/llmeng-1-nb4/r/call/8781ce01-6f57-4f86-9527-8e773ea761d2\n",
      "{\n",
      "  \"question\": \"What is the meaning of life?\",\n",
      "  \"answer\": \"According to the devil the meaning of life is a life of sin and debauchery.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class QuestionAnswer(BaseModel):\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "\n",
    "question = \"What is the meaning of life?\"\n",
    "context = (\n",
    "    \"The according to the devil the meaning of life is a life of sin and debauchery.\"\n",
    ")\n",
    "\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    response_model=QuestionAnswer,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a system that answers questions based on the context. answer exactly what the question asks using the context.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"using the context: `{context}`\\n\\nAnswer the following question: `{question}`\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(resp.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0328bbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍩 https://wandb.ai/a-sh0ts/llmeng-1-nb4/r/call/668888ae-f117-432d-b7b8-d77a637d2f28\n",
      "🍩 https://wandb.ai/a-sh0ts/llmeng-1-nb4/r/call/e3c64170-9843-4c90-ab7b-33051e007596\n",
      "🍩 https://wandb.ai/a-sh0ts/llmeng-1-nb4/r/call/4d461b21-ff12-4bde-953e-000fb196ed17\n",
      "🍩 https://wandb.ai/a-sh0ts/llmeng-1-nb4/r/call/bdc5ca0c-5852-4054-a846-053a96dd8251\n"
     ]
    },
    {
     "ename": "InstructorRetryException",
     "evalue": "RetryError[<Future at 0x14773deb0 state=finished raised ValidationError>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/GitHub/edu/.venv/lib/python3.12/site-packages/instructor/retry.py:193\u001b[0m, in \u001b[0;36mretry_sync\u001b[0;34m(func, response_model, validation_context, args, kwargs, max_retries, strict, mode)\u001b[0m\n\u001b[1;32m    190\u001b[0m                     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m merge_consecutive_messages(\n\u001b[1;32m    191\u001b[0m                         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    192\u001b[0m                     )\n\u001b[0;32m--> 193\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/GitHub/edu/.venv/lib/python3.12/site-packages/instructor/retry.py:164\u001b[0m, in \u001b[0;36mretry_sync\u001b[0;34m(func, response_model, validation_context, args, kwargs, max_retries, strict, mode)\u001b[0m\n\u001b[1;32m    163\u001b[0m     response \u001b[38;5;241m=\u001b[39m update_total_usage(response, total_usage)\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprocess_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ValidationError, JSONDecodeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/GitHub/edu/.venv/lib/python3.12/site-packages/instructor/process_response.py:149\u001b[0m, in \u001b[0;36mprocess_response\u001b[0;34m(response, response_model, stream, validation_context, strict, mode)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m--> 149\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mresponse_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, OpenAISchema):\n",
      "File \u001b[0;32m~/Documents/GitHub/edu/.venv/lib/python3.12/site-packages/instructor/function_calls.py:269\u001b[0m, in \u001b[0;36mOpenAISchema.from_response\u001b[0;34m(cls, completion, validation_context, strict, mode)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m {Mode\u001b[38;5;241m.\u001b[39mTOOLS, Mode\u001b[38;5;241m.\u001b[39mMISTRAL_TOOLS}:\n\u001b[0;32m--> 269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m {Mode\u001b[38;5;241m.\u001b[39mJSON, Mode\u001b[38;5;241m.\u001b[39mJSON_SCHEMA, Mode\u001b[38;5;241m.\u001b[39mMD_JSON}:\n",
      "File \u001b[0;32m~/Documents/GitHub/edu/.venv/lib/python3.12/site-packages/instructor/function_calls.py:433\u001b[0m, in \u001b[0;36mOpenAISchema.parse_tools\u001b[0;34m(cls, completion, validation_context, strict)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    431\u001b[0m     tool_call\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_schema[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m    432\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTool name does not match\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_validate_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtool_call\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/edu/.venv/lib/python3.12/site-packages/pydantic/main.py:597\u001b[0m, in \u001b[0;36mBaseModel.model_validate_json\u001b[0;34m(cls, json_data, strict, context)\u001b[0m\n\u001b[1;32m    596\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for QuestionAnswer\nanswer\n  Assertion failed, The statement contains objectionable content. [type=assertion_error, input_value='A life of sin and debauc...according to the devil.', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.8/v/assertion_error",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/GitHub/edu/.venv/lib/python3.12/site-packages/instructor/retry.py:158\u001b[0m, in \u001b[0;36mretry_sync\u001b[0;34m(func, response_model, validation_context, args, kwargs, max_retries, strict, mode)\u001b[0m\n\u001b[1;32m    157\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mattempt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mattempt\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/edu/.venv/lib/python3.12/site-packages/tenacity/__init__.py:443\u001b[0m, in \u001b[0;36mBaseRetrying.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 443\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
      "File \u001b[0;32m~/Documents/GitHub/edu/.venv/lib/python3.12/site-packages/tenacity/__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Documents/GitHub/edu/.venv/lib/python3.12/site-packages/tenacity/__init__.py:419\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[0;32m--> 419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "\u001b[0;31mRetryError\u001b[0m: RetryError[<Future at 0x14773deb0 state=finished raised ValidationError>]",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInstructorRetryException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m     question: \u001b[38;5;28mstr\u001b[39m\n\u001b[1;32m     14\u001b[0m     answer: NotEvilAnswer\n\u001b[0;32m---> 17\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mQuestionAnswer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a system that answers questions based on the context. answer exactly what the question asks using the context.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing the context: `\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcontext\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m`\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mAnswer the following question: `\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mquestion\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m`\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/edu/.venv/lib/python3.12/site-packages/instructor/patch.py:143\u001b[0m, in \u001b[0;36mpatch.<locals>.new_create_sync\u001b[0;34m(response_model, validation_context, max_retries, strict, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_create_sync\u001b[39m(\n\u001b[1;32m    133\u001b[0m     response_model: \u001b[38;5;28mtype\u001b[39m[T_Model] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: T_ParamSpec\u001b[38;5;241m.\u001b[39mkwargs,\n\u001b[1;32m    139\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T_Model:\n\u001b[1;32m    140\u001b[0m     response_model, new_kwargs \u001b[38;5;241m=\u001b[39m handle_response_model(\n\u001b[1;32m    141\u001b[0m         response_model\u001b[38;5;241m=\u001b[39mresponse_model, mode\u001b[38;5;241m=\u001b[39mmode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    142\u001b[0m     )\n\u001b[0;32m--> 143\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mretry_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Documents/GitHub/edu/.venv/lib/python3.12/site-packages/instructor/retry.py:195\u001b[0m, in \u001b[0;36mretry_sync\u001b[0;34m(func, response_model, validation_context, args, kwargs, max_retries, strict, mode)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 195\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InstructorRetryException(\n\u001b[1;32m    196\u001b[0m         e,\n\u001b[1;32m    197\u001b[0m         last_completion\u001b[38;5;241m=\u001b[39mresponse,\n\u001b[1;32m    198\u001b[0m         n_attempts\u001b[38;5;241m=\u001b[39mattempt\u001b[38;5;241m.\u001b[39mretry_state\u001b[38;5;241m.\u001b[39mattempt_number,\n\u001b[1;32m    199\u001b[0m         messages\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    200\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontents\u001b[39m\u001b[38;5;124m\"\u001b[39m, kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m\"\u001b[39m, []))\n\u001b[1;32m    201\u001b[0m         ),\n\u001b[1;32m    202\u001b[0m         total_usage\u001b[38;5;241m=\u001b[39mtotal_usage,\n\u001b[1;32m    203\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mInstructorRetryException\u001b[0m: RetryError[<Future at 0x14773deb0 state=finished raised ValidationError>]"
     ]
    }
   ],
   "source": [
    "from instructor import llm_validator\n",
    "\n",
    "\n",
    "NotEvilAnswer = Annotated[\n",
    "    str,\n",
    "    AfterValidator(\n",
    "        llm_validator(\"don't say objectionable things\", client=client)\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "class QuestionAnswer(BaseModel):\n",
    "    question: str\n",
    "    answer: NotEvilAnswer\n",
    "\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    response_model=QuestionAnswer,\n",
    "    max_retries=2,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a system that answers questions based on the context. answer exactly what the question asks using the context.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"using the context: `{context}`\\n\\nAnswer the following question: `{question}`\",\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814d3554",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resp.model_dump_json(indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
