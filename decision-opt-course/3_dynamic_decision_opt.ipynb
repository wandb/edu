{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/edu/blob/main/decision-opt-course/3_dynamic_decision_opt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{decisionopt-nb3b} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 3 - Dynamic Decision Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "os.environ[\"WANDB_QUIET\"] = \"true\"\n",
    "project_name = \"Dynamic Inventory Management for Bimbo\"\n",
    "decision_data = pd.read_parquet('decision_data.parquet')\n",
    "decision_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_store_and_product = decision_data.query(\n",
    "\"Agencia_ID == 1110 & Canal_ID == 7 & Ruta_SAK == 3301 & Cliente_ID == 15766 & Producto_ID == 1238\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_product_ids = [\n",
    "    \"Agencia_ID\",\n",
    "    \"Canal_ID\",\n",
    "    \"Ruta_SAK\",\n",
    "    \"Cliente_ID\",\n",
    "    \"Producto_ID\",\n",
    "]\n",
    "\n",
    "numerical_cols = [\n",
    "    \"Venta_uni_hoy\",\n",
    "    \"Venta_hoy\",\n",
    "]\n",
    "\n",
    "model = torch.load(\"predictive_model.pt\")\n",
    "with open('catgeorical_encoder.pkl', 'rb') as f:\n",
    "    encoder = pickle.load(f)\n",
    "\n",
    "categorical_for_prediction = sample_store_and_product[store_product_ids].values\n",
    "categorical_encoded = encoder.transform(categorical_for_prediction)\n",
    "categorical_tensor = torch.from_numpy(categorical_encoded).long()\n",
    "categorical_tensor = [categorical_tensor[:, i] for i in range(categorical_tensor.shape[1])]\n",
    "\n",
    "numerical_tensor = torch.from_numpy(sample_store_and_product[numerical_cols].values).float()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model(categorical_tensor, numerical_tensor)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_store_and_product = sample_store_and_product.assign(predicted_demand = prediction.numpy())\n",
    "sample_store_and_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_preds_to_df(df):\n",
    "    categorical_for_prediction = df[store_product_ids].values\n",
    "    categorical_encoded = encoder.transform(categorical_for_prediction)\n",
    "    categorical_tensor = torch.from_numpy(categorical_encoded).long()\n",
    "    categorical_tensor = [categorical_tensor[:, i] for i in range(categorical_tensor.shape[1])]\n",
    "    numerical_tensor = torch.from_numpy(df[numerical_cols].values).float()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = model(categorical_tensor, numerical_tensor)\n",
    "    return df.assign(predicted_demand = prediction.numpy())\n",
    "\n",
    "sample_store_and_product = decision_data.query(\n",
    "\"Agencia_ID == 1110 & Canal_ID == 7 & Ruta_SAK == 3301 & Cliente_ID == 15766 & Producto_ID == 1238\"\n",
    ")\n",
    "add_preds_to_df(sample_store_and_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_col_with_initial_value(df, col_name, value):\n",
    "    df.loc[df.index[0], col_name] = value\n",
    "    return df\n",
    "\n",
    "def simulate_outcomes(df, decision_rule):\n",
    "    df = df.copy()\n",
    "    df = add_preds_to_df(df)\n",
    "    df = add_col_with_initial_value(df, \"old_stock\", 0)\n",
    "    first_stocking_decision = decision_rule(df.iloc[0])\n",
    "    df = add_col_with_initial_value(df, \"new_stock\", first_stocking_decision)\n",
    "    first_shortage = max(0, df.iloc[0].predicted_demand - df.iloc[0].new_stock)\n",
    "    first_amount_sold = min(df.iloc[0].Demanda_uni_equil, df.iloc[0].new_stock + df.iloc[0].old_stock)\n",
    "    df = add_col_with_initial_value(df, \"shortage\", first_shortage)\n",
    "    df = add_col_with_initial_value(df, \"total_sold\", first_amount_sold)\n",
    "\n",
    "    # Sometimes can use .shift pattern\n",
    "    prev_period = df.iloc[0, :]\n",
    "    for i in df.index[1:]:\n",
    "        df.loc[i, \"old_stock\"] = max(0,\n",
    "                                    min(prev_period.old_stock + prev_period.new_stock - prev_period.Demanda_uni_equil,\n",
    "                                     prev_period.new_stock\n",
    "                                    ))\n",
    "        df.loc[i, \"new_stock\"] = decision_rule(df.loc[i])\n",
    "        stock_on_hand = df.loc[i, \"old_stock\"] + df.loc[i, \"new_stock\"]\n",
    "        df.loc[i, \"shortage\"] = max(0, df.loc[i, \"Demanda_uni_equil\"] - stock_on_hand)\n",
    "        df.loc[i, \"total_sold\"] = min(df.loc[i, \"Demanda_uni_equil\"], stock_on_hand)\n",
    "        df.loc[i, \"spoilage\"] = max(0, df.loc[i, \"old_stock\"] - df.loc[i, \"Demanda_uni_equil\"])\n",
    "        prev_period = df.loc[i]\n",
    "    return df\n",
    "\n",
    "def first_decision_rule(state):\n",
    "    return 1\n",
    "\n",
    "simulate_outcomes(sample_store_and_product, first_decision_rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling to multiple stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_data.groupby('Agencia_ID').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_validation_data = decision_data.query('Agencia_ID == 1110')\n",
    "decision_holdout_data = decision_data.query('Agencia_ID == 24049')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(df):\n",
    "    return df.total_sold.sum() - 3*df.shortage.sum() - 0.5 * df.spoilage.sum() - 0.5*df.old_stock.sum()\n",
    "\n",
    "def log_metrics(outcomes, decision_function, tags=None):\n",
    "    with wandb.init(project=project_name,\n",
    "                    name=decision_function.__name__,\n",
    "                    job_type=\"simulation outcomes\",\n",
    "                    tags=tags\n",
    "                    ):\n",
    "        wandb.log({\n",
    "            \"number_of_orders\": outcomes.new_stock.count(),\n",
    "            \"total_inventory_orders\": outcomes.new_stock.sum(),\n",
    "            \"number_of_shortages\": (outcomes.shortage > 0).sum(),\n",
    "            \"total_shortage\": outcomes.shortage.sum(),\n",
    "            \"total_sold\": outcomes.total_sold.sum(),\n",
    "            \"total_old_stock\": outcomes.old_stock.sum(),\n",
    "            \"full_outcome\": outcomes[store_product_ids + ['Semana', 'old_stock', 'new_stock', 'shortage', 'total_sold', 'spoilage']],\n",
    "            \"objective_function\": objective_function(outcomes)\n",
    "        })\n",
    "    return\n",
    "\n",
    "def simulate_multiple_stores_and_products(raw_data, decision_function, tags, log=True):\n",
    "    groups = raw_data.groupby(store_product_ids)\n",
    "    outcomes = pd.concat([simulate_outcomes(group, decision_function) for _, group in groups])\n",
    "    if log:\n",
    "        log_metrics(outcomes, decision_function, tags)\n",
    "    return outcomes\n",
    "\n",
    "simulate_multiple_stores_and_products(decision_validation_data, first_decision_rule, tags=[\"agencia_1110\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predicted_need(state):\n",
    "    return np.ceil(state.predicted_demand - state.old_stock)\n",
    "\n",
    "def predicted_need_plus_one(state):\n",
    "    return predicted_need(state) + 1\n",
    "\n",
    "def predicted_demand(state):\n",
    "    return np.ceil(state.predicted_demand)\n",
    "\n",
    "for rule in [first_decision_rule, predicted_need, predicted_need_plus_one, predicted_demand]:\n",
    "    simulate_multiple_stores_and_products(decision_validation_data, rule, tags=[\"agencia_1110\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programmatic Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_decision_function_factory(constant, predicted_demand_mult, old_stock_mult):\n",
    "    def decision_function(state):\n",
    "        return constant + predicted_demand_mult * state.predicted_demand + old_stock_mult * state.old_stock\n",
    "    return decision_function\n",
    "\n",
    "def objective(params):\n",
    "    decision_function = linear_decision_function_factory(params.constant, params.predicted_demand_mult, params.old_stock_mult)\n",
    "    outcomes = simulate_multiple_stores_and_products(decision_validation_data, decision_function, tags=[\"agencia_1110\"], log=False)\n",
    "    return objective_function(outcomes)\n",
    "\n",
    "sweep_config = {\n",
    "    'method': 'bayes',\n",
    "    'metric': {\n",
    "        'name': 'objective_function',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'constant': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 0,\n",
    "            'max': 5\n",
    "        },\n",
    "        'predicted_demand_mult': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 0,\n",
    "            'max': 1.5\n",
    "        },\n",
    "        'old_stock_mult': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': -1.5,\n",
    "            'max': 0,\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "def main():\n",
    "    wandb.init(project=project_name)\n",
    "    score = objective(wandb.config)\n",
    "    wandb.log({'objective_function': score})\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=project_name)\n",
    "wandb.agent(sweep_id, main, count=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
