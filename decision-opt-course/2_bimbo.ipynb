{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danbecker/decision_opt_bimbo/runs/xx1b1vzk' target=\"_blank\">vocal-yogurt-74</a></strong> to <a href='https://wandb.ai/danbecker/decision_opt_bimbo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danbecker/decision_opt_bimbo/runs/xx1b1vzk' target=\"_blank\">https://wandb.ai/danbecker/decision_opt_bimbo/runs/xx1b1vzk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   5 of 5 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vocal-yogurt-74</strong> at: <a href='https://wandb.ai/danbecker/decision_opt_bimbo/runs/xx1b1vzk' target=\"_blank\">https://wandb.ai/danbecker/decision_opt_bimbo/runs/xx1b1vzk</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Semana</th>\n",
       "      <th>Agencia_ID</th>\n",
       "      <th>Canal_ID</th>\n",
       "      <th>Ruta_SAK</th>\n",
       "      <th>Cliente_ID</th>\n",
       "      <th>Producto_ID</th>\n",
       "      <th>Venta_uni_hoy</th>\n",
       "      <th>Venta_hoy</th>\n",
       "      <th>Dev_uni_proxima</th>\n",
       "      <th>Dev_proxima</th>\n",
       "      <th>Demanda_uni_equil</th>\n",
       "      <th>NombreCliente</th>\n",
       "      <th>NombreProducto</th>\n",
       "      <th>Town</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1212</td>\n",
       "      <td>3</td>\n",
       "      <td>25.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>PUESTO DE PERIODICOS LAZARO</td>\n",
       "      <td>Roles Canela 2p 120g BIM 1212</td>\n",
       "      <td>2008 AG. LAGO FILT</td>\n",
       "      <td>MÉXICO, D.F.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1216</td>\n",
       "      <td>4</td>\n",
       "      <td>33.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>PUESTO DE PERIODICOS LAZARO</td>\n",
       "      <td>Roles Glass 2p 135g BIM 1216</td>\n",
       "      <td>2008 AG. LAGO FILT</td>\n",
       "      <td>MÉXICO, D.F.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1238</td>\n",
       "      <td>4</td>\n",
       "      <td>39.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>PUESTO DE PERIODICOS LAZARO</td>\n",
       "      <td>Panquecito Gota Choc 2p 140g BIM 1238</td>\n",
       "      <td>2008 AG. LAGO FILT</td>\n",
       "      <td>MÉXICO, D.F.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1240</td>\n",
       "      <td>4</td>\n",
       "      <td>33.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>PUESTO DE PERIODICOS LAZARO</td>\n",
       "      <td>Mantecadas Vainilla 4p 125g BIM 1240</td>\n",
       "      <td>2008 AG. LAGO FILT</td>\n",
       "      <td>MÉXICO, D.F.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1242</td>\n",
       "      <td>3</td>\n",
       "      <td>22.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>PUESTO DE PERIODICOS LAZARO</td>\n",
       "      <td>Donitas Espolvoreadas 6p 105g BIM 1242</td>\n",
       "      <td>2008 AG. LAGO FILT</td>\n",
       "      <td>MÉXICO, D.F.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Semana  Agencia_ID  Canal_ID  Ruta_SAK  Cliente_ID  Producto_ID  \\\n",
       "0       3        1110         7      3301       15766         1212   \n",
       "1       3        1110         7      3301       15766         1216   \n",
       "2       3        1110         7      3301       15766         1238   \n",
       "3       3        1110         7      3301       15766         1240   \n",
       "4       3        1110         7      3301       15766         1242   \n",
       "\n",
       "   Venta_uni_hoy  Venta_hoy  Dev_uni_proxima  Dev_proxima  Demanda_uni_equil  \\\n",
       "0              3      25.14                0          0.0                  3   \n",
       "1              4      33.52                0          0.0                  4   \n",
       "2              4      39.32                0          0.0                  4   \n",
       "3              4      33.52                0          0.0                  4   \n",
       "4              3      22.92                0          0.0                  3   \n",
       "\n",
       "                 NombreCliente                          NombreProducto  \\\n",
       "0  PUESTO DE PERIODICOS LAZARO           Roles Canela 2p 120g BIM 1212   \n",
       "1  PUESTO DE PERIODICOS LAZARO            Roles Glass 2p 135g BIM 1216   \n",
       "2  PUESTO DE PERIODICOS LAZARO   Panquecito Gota Choc 2p 140g BIM 1238   \n",
       "3  PUESTO DE PERIODICOS LAZARO    Mantecadas Vainilla 4p 125g BIM 1240   \n",
       "4  PUESTO DE PERIODICOS LAZARO  Donitas Espolvoreadas 6p 105g BIM 1242   \n",
       "\n",
       "                 Town         State  \n",
       "0  2008 AG. LAGO FILT  MÉXICO, D.F.  \n",
       "1  2008 AG. LAGO FILT  MÉXICO, D.F.  \n",
       "2  2008 AG. LAGO FILT  MÉXICO, D.F.  \n",
       "3  2008 AG. LAGO FILT  MÉXICO, D.F.  \n",
       "4  2008 AG. LAGO FILT  MÉXICO, D.F.  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from pathlib import Path\n",
    "import os\n",
    "import wandb\n",
    "\n",
    "os.environ[\"WANDB_QUIET\"] = \"true\"  # Keep notebook output clean\n",
    "wandb_project = \"decision_opt_bimbo\"\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "# Let's load the data from a W&B artifact\n",
    "with wandb.init(project=wandb_project) as run:\n",
    "    artifact = run.use_artifact(\n",
    "        \"wandb_course/decision_opt/grupo-bimbo-inventory-demand:latest\"\n",
    "    )\n",
    "    data_dir = Path(artifact.download())\n",
    "\n",
    "data = pd.read_csv(data_dir / \"train.csv\")\n",
    "clientes = pd.read_csv(data_dir / \"cliente_tabla.csv\")\n",
    "productos = pd.read_csv(data_dir / \"producto_tabla.csv\")\n",
    "town_state = pd.read_csv(data_dir / \"town_state.csv\")\n",
    "\n",
    "# Merge datasets\n",
    "data = data.merge(clientes, on=\"Cliente_ID\", how=\"left\")\n",
    "data = data.merge(productos, on=\"Producto_ID\", how=\"left\")\n",
    "data = data.merge(town_state, on=\"Agencia_ID\", how=\"left\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categorical columns\n",
    "categorical_cols = [\"Agencia_ID\", \"Canal_ID\", \"Ruta_SAK\", \"Cliente_ID\", \"Producto_ID\"]\n",
    "\n",
    "# Define the label encoder\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(data[col])\n",
    "    data[col] = le.transform(data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "num_unique_vals = {col: data[col].nunique() for col in categorical_cols}\n",
    "embedding_sizes = {col: min(50, num_unique_vals[col] // 2) for col in categorical_cols}\n",
    "\n",
    "# Split into features and target\n",
    "X = data[categorical_cols].values\n",
    "y = data[\"Demanda_uni_equil\"].values\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "# Define the Dataset class\n",
    "class BimboDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = [torch.tensor(X[:, i], dtype=torch.long) for i in range(X.shape[1])]\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [x[idx] for x in self.X], self.y[idx]\n",
    "\n",
    "\n",
    "# Create Datasets and DataLoaders\n",
    "train_dataset = BimboDataset(X_train, y_train)\n",
    "val_dataset = BimboDataset(X_val, y_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, embedding_sizes, hidden_size=128):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.embeddings = nn.ModuleList(\n",
    "            [\n",
    "                nn.Embedding(num_unique_vals[col], embedding_sizes[col])\n",
    "                for col in categorical_cols\n",
    "            ])\n",
    "        self.fc1 = nn.Linear(sum(embedding_sizes.values()), hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = [embedding(x_i) for x_i, embedding in zip(x, self.embeddings)]\n",
    "        x = torch.cat(x, dim=-1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x).squeeze(-1)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train_model(loss_fn, num_epochs=5):\n",
    "    model = SimpleModel(embedding_sizes)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs).squeeze()\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_preds = []\n",
    "        val_targets = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                outputs = model(inputs).squeeze()\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "                val_preds.extend(outputs.tolist())\n",
    "                val_targets.extend(targets.tolist())\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        r2 = r2_score(val_targets, val_preds)\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"train_loss\": train_loss,\n",
    "                \"val_loss\": val_loss,\n",
    "                \"r_squared\": r2,\n",
    "            }\n",
    ")\n",
    "    return model, np.array(val_preds), np.array(val_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_business_metrics(stocking_decisions, actual_demand, name, tags):\n",
    "    with wandb.init(\n",
    "        project=wandb_project,\n",
    "        name=name,\n",
    "        tags=tags,\n",
    "        job_type=\"decision\",\n",
    "    ):\n",
    "        frac_understocks = (stocking_decisions < actual_demand).mean()\n",
    "        total_understocked_amt = (actual_demand - stocking_decisions).clip(0).sum()\n",
    "        frac_overstocks = (stocking_decisions > actual_demand).mean()\n",
    "        total_overstocked_amt = (stocking_decisions - actual_demand).clip(0).sum()\n",
    "        utility = -3 * total_understocked_amt - total_overstocked_amt\n",
    "        mae = mean_absolute_error(actual_demand, stocking_decisions)\n",
    "        mse = mean_squared_error(actual_demand, stocking_decisions)\n",
    "        r2_score(actual_demand, stocking_decisions),\n",
    "\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"frac_understocks\": frac_understocks,\n",
    "                \"total_understocked_amt\": total_understocked_amt,\n",
    "                \"frac_overstocks\": frac_overstocks,\n",
    "                \"total_overstocked_amt\": total_overstocked_amt,\n",
    "                \"utility\": utility,\n",
    "                \"mae\": mae,\n",
    "                \"mse\": mse,\n",
    "                \"r2_score\": r2_score,\n",
    "            }\n",
    "        )\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danbecker/decision_opt_bimbo/runs/fpv0qiej' target=\"_blank\">mse_optimized</a></strong> to <a href='https://wandb.ai/danbecker/decision_opt_bimbo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danbecker/decision_opt_bimbo/runs/fpv0qiej' target=\"_blank\">https://wandb.ai/danbecker/decision_opt_bimbo/runs/fpv0qiej</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mse_optimized</strong> at: <a href='https://wandb.ai/danbecker/decision_opt_bimbo/runs/fpv0qiej' target=\"_blank\">https://wandb.ai/danbecker/decision_opt_bimbo/runs/fpv0qiej</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danbecker/decision_opt_bimbo/runs/z0r3qana' target=\"_blank\">mse_loss_predictions</a></strong> to <a href='https://wandb.ai/danbecker/decision_opt_bimbo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danbecker/decision_opt_bimbo/runs/z0r3qana' target=\"_blank\">https://wandb.ai/danbecker/decision_opt_bimbo/runs/z0r3qana</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mse_loss_predictions</strong> at: <a href='https://wandb.ai/danbecker/decision_opt_bimbo/runs/z0r3qana' target=\"_blank\">https://wandb.ai/danbecker/decision_opt_bimbo/runs/z0r3qana</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "with wandb.init(\n",
    "    project=wandb_project, name=\"mse_optimized\", tags=[\"mse_loss\"]\n",
    "):\n",
    "    loss = nn.MSELoss()\n",
    "    mse_model, mse_val_preds, mse_val_targets = train_model(loss, num_epochs=5)\n",
    "    # save mse_model as artifact\n",
    "    torch.save(mse_model.state_dict(), \"mse_model.pt\")\n",
    "    wandb.save(\"mse_model.pt\")\n",
    "\n",
    "mse_val_stock = np.ceil(mse_val_preds)\n",
    "log_business_metrics(mse_val_stock, mse_val_targets, \"mse_loss_predictions\", tags=[\"mse_loss\", \"stock_predicted_sales\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danbecker/decision_opt_bimbo/runs/xk93az88' target=\"_blank\">50_pct_above_mse_loss_predictions</a></strong> to <a href='https://wandb.ai/danbecker/decision_opt_bimbo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danbecker/decision_opt_bimbo/runs/xk93az88' target=\"_blank\">https://wandb.ai/danbecker/decision_opt_bimbo/runs/xk93az88</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">50_pct_above_mse_loss_predictions</strong> at: <a href='https://wandb.ai/danbecker/decision_opt_bimbo/runs/xk93az88' target=\"_blank\">https://wandb.ai/danbecker/decision_opt_bimbo/runs/xk93az88</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alternative_stocking_rule = np.ceil(1.5 * mse_val_preds)\n",
    "log_business_metrics(alternative_stocking_rule,\n",
    "                     mse_val_targets,\n",
    "                     \"50_pct_above_mse_loss_predictions\",\n",
    "                     tags=[\"mse_loss\", \"stock_50_pct_above_predicted_sales\"]\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danbecker/decision_opt_bimbo/runs/oqkh5dtj' target=\"_blank\">mae_optimized</a></strong> to <a href='https://wandb.ai/danbecker/decision_opt_bimbo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danbecker/decision_opt_bimbo/runs/oqkh5dtj' target=\"_blank\">https://wandb.ai/danbecker/decision_opt_bimbo/runs/oqkh5dtj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mae_optimized</strong> at: <a href='https://wandb.ai/danbecker/decision_opt_bimbo/runs/oqkh5dtj' target=\"_blank\">https://wandb.ai/danbecker/decision_opt_bimbo/runs/oqkh5dtj</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danbecker/decision_opt_bimbo/runs/3xumvkyw' target=\"_blank\">mae_loss_predictions</a></strong> to <a href='https://wandb.ai/danbecker/decision_opt_bimbo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danbecker/decision_opt_bimbo/runs/3xumvkyw' target=\"_blank\">https://wandb.ai/danbecker/decision_opt_bimbo/runs/3xumvkyw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mae_loss_predictions</strong> at: <a href='https://wandb.ai/danbecker/decision_opt_bimbo/runs/3xumvkyw' target=\"_blank\">https://wandb.ai/danbecker/decision_opt_bimbo/runs/3xumvkyw</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with wandb.init(\n",
    "    project=wandb_project, name=\"mae_optimized\", tags=[\"mae_loss\"]\n",
    "):\n",
    "    loss = nn.L1Loss()\n",
    "    mae_model, mae_val_preds, mae_val_targets = train_model(loss, num_epochs=5)\n",
    "\n",
    "mae_val_stock = np.ceil(mae_val_preds)\n",
    "log_business_metrics(mae_val_stock,\n",
    "                    mae_val_targets,\n",
    "                    'mae_loss_predictions',\n",
    "                    tags=[\"mae_loss\", \"stock_predicted_sales\"]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danbecker/decision_opt_bimbo/runs/wmhvy5jt' target=\"_blank\">50_pct_above_mae_loss_predictions</a></strong> to <a href='https://wandb.ai/danbecker/decision_opt_bimbo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danbecker/decision_opt_bimbo/runs/wmhvy5jt' target=\"_blank\">https://wandb.ai/danbecker/decision_opt_bimbo/runs/wmhvy5jt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">50_pct_above_mae_loss_predictions</strong> at: <a href='https://wandb.ai/danbecker/decision_opt_bimbo/runs/wmhvy5jt' target=\"_blank\">https://wandb.ai/danbecker/decision_opt_bimbo/runs/wmhvy5jt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "above_mae_stocking_rule = np.ceil(1.5 * mae_val_preds)\n",
    "log_business_metrics(above_mae_stocking_rule,\n",
    "                     mse_val_targets,\n",
    "                     \"50_pct_above_mae_loss_predictions\",\n",
    "                     tags=[\"mse_loss\", \"stock_50_pct_above_predicted_sales\"]\n",
    "                     )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return to example of understock costing $3 per unit and overstock costing $1 per unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danbecker/regression_decision_opt/runs/5b0mrl3g' target=\"_blank\">our_utility_loss</a></strong> to <a href='https://wandb.ai/danbecker/regression_decision_opt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danbecker/regression_decision_opt/runs/5b0mrl3g' target=\"_blank\">https://wandb.ai/danbecker/regression_decision_opt/runs/5b0mrl3g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">our_utility_loss</strong> at: <a href='https://wandb.ai/danbecker/regression_decision_opt/runs/5b0mrl3g' target=\"_blank\">https://wandb.ai/danbecker/regression_decision_opt/runs/5b0mrl3g</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danbecker/decision_opt_bimbo/runs/mi7r8afu' target=\"_blank\">utility_fn_loss_predictions</a></strong> to <a href='https://wandb.ai/danbecker/decision_opt_bimbo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danbecker/decision_opt_bimbo/runs/mi7r8afu' target=\"_blank\">https://wandb.ai/danbecker/decision_opt_bimbo/runs/mi7r8afu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">utility_fn_loss_predictions</strong> at: <a href='https://wandb.ai/danbecker/decision_opt_bimbo/runs/mi7r8afu' target=\"_blank\">https://wandb.ai/danbecker/decision_opt_bimbo/runs/mi7r8afu</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "\n",
    "    def forward(self, outputs, actual):\n",
    "        diff = outputs - actual\n",
    "        loss = torch.where(outputs > actual, diff, -3 * diff)\n",
    "        return loss.mean()\n",
    "\n",
    "\n",
    "with wandb.init(\n",
    "    project=\"regression_decision_opt\", name=\"our_utility_loss\", tags=[\"custom_loss\"]\n",
    "):\n",
    "    custom_model, custom_val_preds, custom_val_targets = train_model(\n",
    "        CustomLoss(), num_epochs=5\n",
    "    )\n",
    "\n",
    "custom_val_stock = np.ceil(custom_val_preds)\n",
    "log_business_metrics(custom_val_stock, custom_val_targets, 'utility_fn_loss_predictions', tags=['stock_predicted_sales'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Full Distributions\n",
    "\n",
    "Using QuantileRegressionForest: https://scikit-garden.github.io/examples/QuantileRegressionForests/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestQuantileRegressor(min_samples_leaf=50, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestQuantileRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestQuantileRegressor(min_samples_leaf=50, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestQuantileRegressor(min_samples_leaf=50, random_state=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from quantile_forest import RandomForestQuantileRegressor\n",
    "\n",
    "qrf = RandomForestQuantileRegressor(\n",
    "    n_estimators=100, min_samples_leaf=50, random_state=0\n",
    ")\n",
    "qrf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [i / 100 for i in range(5, 100, 5)]\n",
    "sample_preds = qrf.predict(X_val, quantiles=quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.  ,  2.  ,  2.  ,  2.  ,  3.  ,  3.  ,  4.  ,  4.  ,  4.55,\n",
       "        5.  ,  6.  ,  7.  ,  7.  ,  8.  ,  9.  , 10.  , 11.  , 11.1 ,\n",
       "       13.1 ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_demand_prediction = sample_preds[5]\n",
    "one_demand_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def rarely_run_out_rule(prediction):\n",
    "    outlier_bound = 3 * np.mean(prediction)\n",
    "    to_stock = math.ceil(min(prediction[-2], outlier_bound))\n",
    "    return to_stock\n",
    "\n",
    "rarely_run_out_rule(one_demand_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005668956753107502"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stocking_decisions = np.apply_along_axis(rarely_run_out_rule, 1, sample_preds)\n",
    "(all_stocking_decisions < sample_preds[:, -2]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danbecker/decision_opt_bimbo/runs/phzxttjd' target=\"_blank\">capped_90th_percentile</a></strong> to <a href='https://wandb.ai/danbecker/decision_opt_bimbo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danbecker/decision_opt_bimbo/runs/phzxttjd' target=\"_blank\">https://wandb.ai/danbecker/decision_opt_bimbo/runs/phzxttjd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">capped_90th_percentile</strong> at: <a href='https://wandb.ai/danbecker/decision_opt_bimbo/runs/phzxttjd' target=\"_blank\">https://wandb.ai/danbecker/decision_opt_bimbo/runs/phzxttjd</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_business_metrics(all_stocking_decisions, y_val, 'capped_90th_percentile', tags=['probabilistic_forecast'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   126,    295,    298,    524,    528,    726,    730,   1175,\n",
       "          1281,   1626,   1649,   1728,   1868,   2136,   2180,   2247,\n",
       "          2402,   2486,   2508,   2514,   2987,   3073,   3545,   3752,\n",
       "          3999,   4104,   4640,   4900,   4950,   4989,   5063,   5102,\n",
       "          5121,   5233,   5270,   5443,   5448,   5463,   6211,   6334,\n",
       "          6373,   6414,   6543,   6783,   6911,   7769,   7929,   7996,\n",
       "          8098,   8385,   8391,   8553,   8577,   8607,   8725,   8727,\n",
       "          8738,   8763,   9482,   9642,  10018,  10132,  10369,  10666,\n",
       "         11471,  11499,  11836,  11973,  11981,  12133,  12248,  12278,\n",
       "         12481,  12489,  12702,  12984,  12990,  13005,  13165,  13429,\n",
       "         13504,  13665,  13714,  14206,  14296,  14539,  14634,  14954,\n",
       "         15169,  15243,  15428,  15630,  15636,  15984,  16113,  16116,\n",
       "         17015,  17026,  17180,  17345,  17352,  17473,  17618,  17690,\n",
       "         17844,  17878,  18164,  18220,  18261,  18659,  18815,  18975,\n",
       "         19075,  19188,  19238,  19244,  19340,  19603,  19927,  20139,\n",
       "         21138,  21201,  21244,  21293,  21499,  21646,  21724,  21883,\n",
       "         21936,  22305,  22485,  22734,  22988,  23153,  23184,  23229,\n",
       "         23283,  23399,  23713,  23831,  23970,  24191,  24373,  24432,\n",
       "         25276,  25498,  25549,  25759,  26054,  26222,  26598,  26899,\n",
       "         27538,  27828,  27854,  27872,  27882,  28109,  28207,  28249,\n",
       "         28710,  28786,  28813,  28977,  29312,  29622,  29795,  29897,\n",
       "         30047,  30086,  30135,  30368,  30519,  30756,  31012,  31134,\n",
       "         31333,  31679,  31905,  32022,  32280,  32548,  32743,  32883,\n",
       "         32934,  33000,  33207,  33348,  33375,  33377,  33683,  33925,\n",
       "         34451,  34606,  34751,  34952,  34988,  35199,  35480,  35561,\n",
       "         35612,  35617,  35833,  36197,  36214,  36337,  36944,  37219,\n",
       "         37416,  37467,  37736,  37748,  37847,  37946,  38304,  38331,\n",
       "         38345,  38488,  39291,  39426,  39591,  39732,  39949,  39967,\n",
       "         40003,  40032,  40045,  40138,  40191,  40408,  40494,  40623,\n",
       "         40719,  40746,  40760,  40819,  41121,  41291,  41398,  42439,\n",
       "         42668,  42680,  42869,  43145,  43155,  43207,  43273,  43436,\n",
       "         43774,  44143,  44155,  44177,  44194,  44268,  44272,  44365,\n",
       "         44503,  44566,  44624,  44989,  45013,  45319,  45464,  45591,\n",
       "         45898,  45908,  46039,  46207,  46642,  46748,  46832,  46850,\n",
       "         46928,  47050,  47182,  47462,  47544,  47558,  47774,  47972,\n",
       "         47995,  48010,  48056,  48468,  48527,  48555,  48611,  48626,\n",
       "         48682,  48684,  49233,  49355,  49627,  49977,  49986,  50009,\n",
       "         50193,  50428,  50778,  51278,  51314,  51392,  51455,  51615,\n",
       "         51626,  51631,  51718,  51775,  51796,  51843,  52149,  52477,\n",
       "         52624,  52660,  52867,  52868,  52893,  52924,  52936,  52995,\n",
       "         53029,  53035,  53102,  53367,  53535,  53574,  53871,  53941,\n",
       "         54058,  54242,  54289,  54339,  54408,  54619,  54739,  54842,\n",
       "         54978,  55034,  55076,  55148,  55172,  55192,  56139,  57604,\n",
       "         58003,  58206,  58403,  58826,  58943,  59022,  59159,  59294,\n",
       "         59580,  59781,  60057,  60180,  60439,  60569,  60935,  60966,\n",
       "         61056,  61085,  61310,  62024,  62134,  62270,  62303,  62565,\n",
       "         62639,  62658,  62729,  62734,  62737,  62823,  62832,  63452,\n",
       "         63534,  63911,  64157,  64349,  64362,  64464,  64484,  64792,\n",
       "         64841,  64886,  65098,  65207,  65347,  65531,  65635,  65642,\n",
       "         65888,  66027,  66116,  66285,  66388,  66575,  66892,  66902,\n",
       "         67005,  67153,  67481,  67525,  67704,  68005,  68025,  68048,\n",
       "         68151,  68242,  68417,  68434,  68606,  68704,  68756,  69113,\n",
       "         69140,  69303,  69377,  69496,  69917,  69953,  70031,  70370,\n",
       "         70563,  71433,  71583,  71736,  71754,  71890,  71981,  72364,\n",
       "         72836,  73133,  73621,  73950,  74114,  74611,  74686,  74857,\n",
       "         75192,  75486,  75489,  75519,  75553,  75798,  76003,  76305,\n",
       "         76549,  76888,  76891,  77076,  77288,  77416,  77824,  77913,\n",
       "         78082,  78287,  78384,  78639,  78890,  78981,  78997,  79137,\n",
       "         79312,  79348,  79411,  79607,  79901,  80040,  80605,  80610,\n",
       "         80675,  80711,  80832,  81110,  81216,  81330,  81442,  81579,\n",
       "         82136,  83014,  83110,  83151,  83163,  83194,  83224,  83379,\n",
       "         83790,  83876,  83913,  84375,  84652,  84675,  85380,  86076,\n",
       "         86213,  86215,  86235,  86672,  86734,  86854,  86862,  86965,\n",
       "         87258,  87515,  87609,  87613,  87682,  87892,  88082,  88333,\n",
       "         88363,  88488,  88847,  89106,  89176,  89183,  89199,  89212,\n",
       "         89869,  89954,  90049,  90544,  90790,  91254,  91358,  91450,\n",
       "         92028,  92214,  92419,  92698,  92899,  92993,  93027,  93102,\n",
       "         93305,  93651,  93845,  94327,  94382,  94411,  94477,  94649,\n",
       "         94756,  94882,  95026,  95177,  95665,  96163,  96322,  96807,\n",
       "         96970,  97022,  97136,  97140,  97222,  97233,  97898,  98152,\n",
       "         98317,  98513,  98695,  99138,  99212,  99554,  99571,  99747,\n",
       "        100144, 100278, 100707]),)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(all_stocking_decisions < sample_preds[:, -2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stocked: 1 when demand was [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "print(f\"stocked: {all_stocking_decisions[126]} when demand was {sample_preds[126, :]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stocked: 2. Input [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.3 1.  1.  2.  2.\n",
      " 4. ]\n",
      "stocked: 1. Input [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 2. 3.]\n",
      "stocked: 27. Input [ 1.    1.    2.    2.    2.    3.    3.    3.    4.    5.    5.    5.\n",
      "  6.    8.   10.   11.2  19.15 30.   45.25]\n",
      "stocked: 24. Input [ 1.    1.    2.    2.    2.    2.    3.    3.    4.    4.5   5.    5.\n",
      "  6.    6.    9.25 12.   15.   26.2  40.4 ]\n",
      "stocked: 2. Input [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 2. 4.]\n",
      "stocked: 1. Input [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   1.   1.   1.05]\n",
      "stocked: 16. Input [ 1.    1.    1.85  2.    2.    2.    2.65  3.    3.    4.    4.    5.\n",
      "  5.    6.    6.    7.2  10.3  15.2  30.9 ]\n"
     ]
    }
   ],
   "source": [
    "for row in [0, 126, 295, 298, 557, 620, 882]:\n",
    "    print(f\"stocked: {all_stocking_decisions[row]}. Input {sample_preds[row, :]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
